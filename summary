import nltk
from nltk.corpus import stopwords
from transformers import pipeline

# 下载停用词
nltk.download('stopwords')

# 加载ChatGPT模型
chatgpt = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')

# 加载停用词
stop_words = set(stopwords.words('english'))

# 定义一个函数来清洗kol内容
def clean_kol_content(content):
    # 分词
    words = nltk.word_tokenize(content)
    
    # 去除停用词
    words = [word for word in words if word.lower() not in stop_words]
    
    # 词形还原
    lemmatizer = nltk.WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    
    # 命名实体识别
    
    # 返回清洗后的内容
    return ' '.join(words)

# 定义一个函数来调用ChatGPT模型进行内容统计总结
def summarize_content(content):
    # 调用ChatGPT模型生成摘要
    summary = chatgpt(content, max_length=100, do_sample=False)[0]['generated_text']
    
    # 返回摘要
    return summary

# 加载kol内容
with open('kol.txt', 'r') as f:
    content = f.read()

# 清洗kol内容
cleaned_content = clean_kol_content(content)

# 进行内容统计总结
summary = summarize_content(cleaned_content)

# 将结果储存到本地文件中
with open('summary.txt', 'w') as f:
    f.write(summary)
